# 20220506学习小结
## 何为CNN
![20220506何为CNN.png](https://s2.loli.net/2022/05/06/w91KbFjXJPmshLv.png)
## 卷积层
* 全连接层（Affine）的缺点：忽视了数据的形状
* **卷积的运算：** 卷积运算以一定间隔滑动滤波器的窗口并应用。将各个位置上滤波器的元素和输入的对应元素相乘，然后再求和（有时将这个计算称为乘积累加运算）。然后，将这个结果保存到输出的对应位置。将这个过程在所有位置都进行一遍，就可以得到卷积运算的输出。
![20220506卷积运算偏置.png](https://s2.loli.net/2022/05/06/jKWfdkQt97ZApsg.png)
![20220506卷积运算顺序.png](https://s2.loli.net/2022/05/06/cxTMLGQWKAIr159.png)
* **填充** 在进行卷积层的处理之前，有时要向输入数据的周围填入固定的数据（比如0等），这称为填充（padding），是卷积运算中经常会用到的处理。**填充的目的是为了调整输出的大小**
  ![20220506卷积填充.png](https://s2.loli.net/2022/05/06/nXivTpaE29CRJZD.png)
* **步幅** 应用滤波器的位置间隔称为步幅（stride）。之前的例子中步幅都是1，如果将步幅设为2，则如图。
  ![20220506卷积步幅.png](https://s2.loli.net/2022/05/06/bBYtDHzSG269rQx.png)
* **输出形状公式**
  ![20220506卷积输出大小公式.png](https://s2.loli.net/2022/05/06/elQiz37RIaJxCs5.png)
* **多维运算的卷积批处理**（***注意滤波器通道数要等于输入数据通道数***）
  ![20220506多维卷积批处理.png](https://s2.loli.net/2022/05/06/jU7Xvzq8YM2xrL3.png)
* **实现：基于im2col的降维处理**
![20220506卷积层im2col.png](https://s2.loli.net/2022/05/06/6jPeq7I8H4EXlv3.png)
![20220506卷积层im2col整体处理.png](https://s2.loli.net/2022/05/06/GhNc7EKjHzrADp3.png)  
```python
  #卷积层实现
class Convolution:
    def __init__(self,W,b,stride = 1,pad = 0) :
        self.W = W
        self.b = b
        self.stride = stride
        self.pad = pad

    def forward(self,x):
        #初始形状处理
        FN,C,FH,FW = self.W.shape
        N,C,H,W = x.shape
        #输出形状预处理
        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)
        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)
        #展开并卷积
        col = im2col(x,FH,FW,self.stride,self.pad)#展开输入数据
        col_W = self.W.reshape(FN,-1).T#展开滤波器,FN个1列的矩阵
        out = np.dot(col,col_W)+self.b

        out = out.reshape(N,out_h,out_w,-1).transpose(0,3,1,2)
        return out
```
## 池化层
池化是缩小高、长方向上的空间的运算。例如：Max池化层
![20220506卷积池化层.png](https://s2.loli.net/2022/05/06/XAHc3rIe1tvZ9SF.png)
池化层特征如下：
![20220506卷积池化层特征1.png](https://s2.loli.net/2022/05/06/eaNtdoQ35uTg4Hk.png)
![20220506卷积池化层特征2.png](https://s2.loli.net/2022/05/06/lEoNMgmRKfOdPHU.png)
* **实现**
  ![20220506卷积池化层实现处理.png](https://s2.loli.net/2022/05/06/xT8ZaSGbvRKhOLf.png)
```python
#池化层的实现
class Pooling:
    def __init__(self,pool_h,pool_w,stride = 1,pad = 0):
        self.pool_h = pool_h
        self.pool_w = pool_w
        self.stride = stride
        self.pad = pad

    def forward(self,x):
        #初始形状处理
        N,C,H,W = x.shape
        #输出形状预处理
        out_h = int(1 + (H + 2*self.pad - self.pool_h) / self.stride)
        out_w = int(1 + (W + 2*self.pad - self.pool_w) / self.stride)
        #展开1
        col = im2col(x,self.pool_h,self.pool_w,self.stride,self.pad)
        col = col.reshape(-1,self.pool_h*self.pool_w)#列数为池化窗口长宽之积
        #最大值2
        out = np.max(col,axis = 1)
        out = out.reshape(N,out_h,out_w,C).transpose(0,3,1,2)
        return out
```
## CNN的实现
* CNN的网络图![20220506简单CNN网络构成.png](https://s2.loli.net/2022/05/06/lnsBxDIvb89CAfG.png)
* CNN参数设置![20220506简单CNN参数设置.png](https://s2.loli.net/2022/05/06/dImwSlvh7Wc9FQJ.png)
## CNN基于分层结构的信息提取
* 如果堆叠了多层卷积层，则随着层次加深，提取的信息也愈加复杂、抽象，这是深度学习中很有意思的一个地方。最开始的层对简单的边缘有响应，接下来的层对纹理有响应，再后面的层对更加复杂的物体部件有响应。也就是说，随着层次加深，神经元从简单的形状向“高级”信息变化。换句话说，就像我们理解东西的“含义”一样，响应的对象在逐渐变化。
# 昨日：超参数优化方法：贝叶斯最优化
## 疑问：卷积实现的reshape在做什么？为什么要-1，为什么顺序变了？
